{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial.distance import minkowski, euclidean, mahalanobis\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob(\"climate_out/*.jpg\")\n",
    "n = len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化列表來存儲每個frame\n",
    "imgs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料夾中的所有影格\n",
    "for path in tqdm.tqdm(paths):\n",
    "    img = cv2.imread(path)\n",
    "    imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化列表來存儲每個frame的特徵\n",
    "color_histogram_features = []\n",
    "region_histogram_features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extract Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color_istogram\n",
    "def color_histogram(img, bins=(8, 8, 8)):\n",
    "    hist = cv2.calcHist([img], [0, 1, 2], None, bins, [0, 256, 0, 256, 0, 256])\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "    return hist\n",
    "\n",
    "# Region\n",
    "def region_histogram(img, num_regions=8):\n",
    "    height, width = img.shape[:2]\n",
    "    region_height, region_width = height // num_regions, width // num_regions\n",
    "    \n",
    "    region_hists = []\n",
    "    for i in range(num_regions):\n",
    "        for j in range(num_regions):\n",
    "            region = img[i*region_height:(i+1)*region_height, j*region_width:(j+1)*region_width]\n",
    "            hist = cv2.calcHist([region], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "            hist = cv2.normalize(hist, hist).flatten()\n",
    "            region_hists.append(hist)\n",
    "    \n",
    "    return np.concatenate(region_hists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in tqdm.tqdm(imgs):\n",
    "    color_histogram_features.append(color_histogram(img))\n",
    "    region_histogram_features.append(region_histogram(img))\n",
    "\n",
    "color_histogram_features = np.array(color_histogram_features)\n",
    "region_histogram_features = np.array(region_histogram_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Descriptor Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D1: Histogram Intersection\n",
    "def D1(hist1, hist2):\n",
    "    return minkowski(hist1, hist2, p=1)\n",
    "\n",
    "# D2: Euclidean Distance\n",
    "def D2(hist1, hist2):\n",
    "    return minkowski(hist1, hist2, p=2)\n",
    "\n",
    "# D5: Histogram Euclidean Distance (與 D2 相同)\n",
    "def D5(hist1, hist2):\n",
    "    return euclidean(hist1, hist2)\n",
    "\n",
    "# D6: Histogram Chi-Square Distance\n",
    "def D6(hist1, hist2):\n",
    "    return np.sum((hist1 - hist2) ** 2 / (hist1 + hist2 + np.finfo(float).eps))\n",
    "\n",
    "# D7: Histogram Correlation Distance\n",
    "def D7(hist1, hist2):\n",
    "    return 1 - np.sum((hist1 - np.mean(hist1)) * (hist2 - np.mean(hist2))) / np.sqrt(np.sum((hist1 - np.mean(hist1)) ** 2) * np.sum((hist2 - np.mean(hist2)) ** 2))\n",
    "\n",
    "# D8: Histogram Bhattacharyya Distance\n",
    "def D8(hist1, hist2):\n",
    "    return -np.log(np.sum(np.sqrt(hist1 * hist2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shot Boundary Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detector(features, distance, threshold):\n",
    "    detect = np.zeros(n)\n",
    "    for i in range(len(features) - 1):\n",
    "        dist = distance(features[i], features[i + 1])\n",
    "        if dist > threshold:\n",
    "            detect[i+1] = 1\n",
    "    return detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從文件中讀取實際的shot boundaries\n",
    "actual = np.zeros(n)\n",
    "with open(\"climate_ground.txt\", \"r\") as f:\n",
    "    lines = f.readlines()[4:]  # 跳過前5行\n",
    "    for line in lines:\n",
    "        if \"~\" in line:\n",
    "            start, end = line.strip().split(\"~\")\n",
    "            actual[int(start):int(end)+1] = 1  # 將指定範圍內的位置設置為1\n",
    "        else:\n",
    "            position = int(line.strip())\n",
    "            actual[position] = 1  # 將指定位置設置為1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(features, distance, feature_name, distance_name):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    tprs = []\n",
    "    fprs = []\n",
    "    for threshold in np.arange(0, 1, 0.2):\n",
    "        predict = detector(features, distance, threshold)\n",
    "        # Calculating TP, FP, TN, FN\n",
    "        tn, fp, fn, tp = confusion_matrix(actual, predict).ravel()\n",
    "        # Calculating precision, recall, F1 score\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "        # Calculating TPR and FPR\n",
    "        tpr = tp / (tp + fn)\n",
    "        fpr = fp / (fp + tn)\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "        tprs.append(tpr)\n",
    "        fprs.append(fpr)\n",
    "\n",
    "    return precisions, recalls, f1_scores, tprs, fprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建一個字典來存儲特徵和距離函數的名字\n",
    "features = {'Color': color_histogram_features, 'Region': region_histogram_features}#, 'Region': region_histogram_features}\n",
    "\n",
    "distances = {\"D1\": D1, \"D2\": D2, \"D5\": D5, \"D6\": D6, \"D7\": D7, \"D8\": D8}\n",
    "# distances = {\"D2\": D2, \"D4\": D4, \"D8\": D8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr_curves(precisions_dict, recalls_dict, feature_name):\n",
    "    linestyles = ['dotted', 'dashed', 'dashdot']\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for i, (distance_name, precisions) in enumerate(precisions_dict.items()):\n",
    "        recalls = recalls_dict[distance_name]\n",
    "        plt.plot(recalls, precisions, linestyle=linestyles[i%3], marker='o', alpha=0.9, label=distance_name)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curves ({feature_name})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curves(tprs_dict, fprs_dict, feature_name):\n",
    "    linestyles = ['dotted', 'dashed', 'dashdot']\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for i, (distance_name, tprs) in enumerate(tprs_dict.items()):\n",
    "        fprs = fprs_dict[distance_name]\n",
    "        plt.plot(fprs, tprs, linestyle=linestyles[i%3], marker='o', alpha=0.9, label=distance_name)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guess')\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curves ({feature_name})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all combinations of features and distance functions, and record the best F1 score\n",
    "for feature_name, feature in features.items():\n",
    "    precisions_dict = {}\n",
    "    recalls_dict = {}\n",
    "    tprs_dict = {}\n",
    "    fprs_dict = {}\n",
    "    f1_dict = {}\n",
    "    \n",
    "    for distance_name, distance in distances.items():\n",
    "        print(f\"Evaluating {feature_name} with {distance_name}...\")\n",
    "        precisions, recalls, f1, tprs, fprs = eval(feature, distance, feature_name, distance_name)\n",
    "        precisions_dict[distance_name] = precisions\n",
    "        recalls_dict[distance_name] = recalls\n",
    "        tprs_dict[distance_name] = tprs\n",
    "        fprs_dict[distance_name] = fprs\n",
    "        f1_dict[distance_name] = f1\n",
    "    print(f1_dict)\n",
    "    plot_pr_curves(precisions_dict, recalls_dict, feature_name)\n",
    "    plot_roc_curves(tprs_dict, fprs_dict, feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cchs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
